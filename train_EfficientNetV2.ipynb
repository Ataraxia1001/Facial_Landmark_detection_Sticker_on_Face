{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cde14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09035f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "# from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import EfficientNetV2M\n",
    "from tensorflow.keras.applications import EfficientNetV2B0\n",
    "\n",
    "from tensorflow.keras.optimizers.legacy import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73982d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import mixed_precision\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Set GPU memory growth\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth must be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaba1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global image_h\n",
    "global image_w\n",
    "global num_landmarks\n",
    "\n",
    "\"\"\" Hyperparameters \"\"\"\n",
    "image_h = 224\n",
    "image_w = 224\n",
    "num_landmarks = 106\n",
    "input_shape = (image_h, image_w, 3)\n",
    "batch_size = 32\n",
    "lr = 0.001\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78946a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=100000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bc57b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" Seeding \"\"\"\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aebe610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Paths \"\"\"\n",
    "path = \"./LaPa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c857bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.jpg\")))\n",
    "# 4. train_img = [ '이미지 경로1 ', '이미지경로2', ...]\n",
    "train_land = sorted(glob(os.path.join(path, \"train\", \"landmarks\", \"*.txt\")))\n",
    "# 4-1. train_img = [ 'landmarks경로1 ', 'landmarks경로2', ...]\n",
    "valid_img = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.jpg\")))\n",
    "valid_land = sorted(glob(os.path.join(path, \"val\", \"landmarks\", \"*.txt\")))\n",
    "test_img = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.jpg\")))\n",
    "test_land = sorted(glob(os.path.join(path, \"test\", \"landmarks\", \"*.txt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065ea98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce size of data\n",
    "train_img = train_img[0:2000]\n",
    "train_land = train_land[0:2000]\n",
    "valid_img = valid_img[0:400]\n",
    "valid_land = valid_land[0:400]\n",
    "test_img = test_img[0:400]\n",
    "test_land = test_land[0:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6c04c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 2000 400 400 400 400\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img), len(train_land), len(valid_img), len(valid_land), len(test_img), len(test_land))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e5e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_landmarks(image_path, landmark_path):\n",
    "    # 6. \n",
    "    # 6-1 . 이미지경로 뭉탱이, 랜드마크경로 뭉탱이\n",
    "    \"\"\" Image \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    h, w, _ = image.shape\n",
    "    image = cv2.resize(image, (image_w, image_h))\n",
    "    \n",
    "    # Cast the image data to float32\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image /= 255.0\n",
    "  #  image = image.astype(np.float32)\n",
    "\n",
    "    \"\"\" Landmarks \"\"\"\n",
    "    data = open(landmark_path, \"r\").read()\n",
    "    landmarks = []\n",
    "\n",
    "    for line in data.strip().split(\"\\n\")[1:]:\n",
    "        x, y = line.split(\" \")\n",
    "        x = float(x)/w\n",
    "        y = float(y)/h\n",
    "\n",
    "        landmarks.append(x)\n",
    "        landmarks.append(y)\n",
    "\n",
    "    landmarks = np.array(landmarks, dtype=np.float32)\n",
    "\n",
    "    return image, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "031d70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    # 뭉탱이1[0], 뭉탱이2[0]\n",
    "    # 이미지경로 하나, 랜드마크 경로 하나 씩\n",
    "    def f(x, y):\n",
    "        x = x.decode()\n",
    "        # b'./lbsdf/image'\n",
    "        y = y.decode()\n",
    "\n",
    "        image, landmarks = read_image_landmarks(x, y)\n",
    "        return image, landmarks\n",
    "\n",
    "    # 5. x = <'이미지경로1', '2'> / y= <'랜드마크경로1', '2'>\n",
    "    image, landmarks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
    "    image.set_shape([image_h, image_w, 3])\n",
    "    landmarks.set_shape([num_landmarks * 2])\n",
    "\n",
    "    return image, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "addac252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_landmarks):\n",
    "    inputs = L.Input(input_shape)\n",
    "\n",
    "#   backbone = MobileNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs, alpha=0.5)\n",
    "    backbone = EfficientNetV2B0(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    backbone.trainable = True\n",
    "\n",
    "    x = backbone.output\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    outputs = L.Dense(num_landmarks*2, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b6434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80002c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27ad24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((train_img, train_land))\n",
    "# 3. ds_train = ( 텐서'이미지경로', 텐서'랜드마크')\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((valid_img, valid_land))\n",
    "\n",
    "# for i in ds_train:\n",
    "#     print(\"type(i) : \",type(i))\n",
    "#     print(i)\n",
    "#     print(i[0])\n",
    "#     print(i[1])\n",
    "#     print('-----------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d92f483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ShuffleDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = ds_train.shuffle(buffer_size=100)\n",
    "# 2 ds_train= 튜플 / x = tensor1 , y=tensor2\n",
    "ds_valid = ds_valid.shuffle(buffer_size=100)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db37aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(212,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = ds_train.map(preprocess)\n",
    "# 1. preprocess(x,y) #가정 map 하나씩 적용\n",
    "ds_valid = ds_valid.map(preprocess)\n",
    "# map( lambda x,y :  preprocess(x,y) , ds_valid)\n",
    "# map(preprocess , ds_valid)\n",
    "# ds_valid.map(preprocess)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9107fb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 212), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = ds_train.batch(batch_size).prefetch(2)\n",
    "ds_valid = ds_valid.batch(batch_size).prefetch(2)\n",
    "# Most dataset input pipelines should end with a call to prefetch. \n",
    "# This allows later elements to be prepared while the current element is being processed. \n",
    "# This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e0fc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"model_result\", \"model_effi.h5\")\n",
    "csv_path = os.path.join(\"model_result\", \"data_effi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88d03bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model \"\"\"\n",
    "model = build_model(input_shape, num_landmarks)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr_schedule))\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path, append=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48393d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60/63 [===========================>..] - ETA: 9:47 - loss: 0.6698 "
     ]
    }
   ],
   "source": [
    "model.fit(ds_train,\n",
    "        validation_data=ds_valid,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29:58:42  -> 3:12:48 after reducing data size (224*224)\n",
    "\n",
    "# learning rate schedule (224*224) 2:39:53, \n",
    "# but loss:2.8818 -> ini lr = 0.01 then loss 0.7004 -> 0.7806->0.7242->0.7200->0.7073"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b8ce41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e4348b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
