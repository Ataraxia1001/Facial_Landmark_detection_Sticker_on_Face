{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cde14ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09035f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as L\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras.applications import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaba1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global image_h\n",
    "global image_w\n",
    "global num_landmarks\n",
    "\n",
    "\"\"\" Hyperparameters \"\"\"\n",
    "image_h = 512\n",
    "image_w = 512\n",
    "num_landmarks = 106\n",
    "input_shape = (image_h, image_w, 3)\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aebe610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Paths \"\"\"\n",
    "path = \"./LaPa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c857bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.jpg\")))\n",
    "train_land = sorted(glob(os.path.join(path, \"train\", \"landmarks\", \"*.txt\")))\n",
    "valid_img = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.jpg\")))\n",
    "valid_land = sorted(glob(os.path.join(path, \"val\", \"landmarks\", \"*.txt\")))\n",
    "test_img = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.jpg\")))\n",
    "test_land = sorted(glob(os.path.join(path, \"test\", \"landmarks\", \"*.txt\")))\n",
    "# train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c04c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_img = train_img.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34e5e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_lankmarks(image_path, landmark_path):\n",
    "    \"\"\" Image \"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    h, w, _ = image.shape\n",
    "    image = cv2.resize(image, (image_w, image_h))\n",
    "    \n",
    "    # Cast the image data to float32\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    image /= 255.0\n",
    "  #  image = image.astype(np.float32)\n",
    "\n",
    "    \"\"\" Lankmarks \"\"\"\n",
    "    data = open(landmark_path, \"r\").read()\n",
    "    lankmarks = []\n",
    "\n",
    "    for line in data.strip().split(\"\\n\")[1:]:\n",
    "        x, y = line.split(\" \")\n",
    "        x = float(x)/w\n",
    "        y = float(y)/h\n",
    "\n",
    "        lankmarks.append(x)\n",
    "        lankmarks.append(y)\n",
    "\n",
    "    lankmarks = np.array(lankmarks, dtype=np.float32)\n",
    "\n",
    "    return image, lankmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "031d70ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    def f(x, y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "\n",
    "        image, landmarks = read_image_lankmarks(x, y)\n",
    "        return image, landmarks\n",
    "\n",
    "    image, landmarks = tf.numpy_function(f, [x, y], [tf.float32, tf.float32])\n",
    "    image.set_shape([image_h, image_w, 3])\n",
    "    landmarks.set_shape([num_landmarks * 2])\n",
    "\n",
    "    return image, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "addac252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_landmarks):\n",
    "    inputs = L.Input(input_shape)\n",
    "\n",
    "    backbone = MobileNetV2(include_top=False, weights=\"imagenet\", input_tensor=inputs, alpha=0.5)\n",
    "    backbone.trainable = True\n",
    "\n",
    "    x = backbone.output\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    x = L.Dropout(0.2)(x)\n",
    "    outputs = L.Dense(num_landmarks*2, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b6434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80002c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27ad24d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((train_img, train_land))\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((valid_img, valid_land))\n",
    "\n",
    "# for i in ds_train:\n",
    "#     print(i)\n",
    "#     print(i[0])\n",
    "#     print(i[1])\n",
    "#     print('-----------------------------------------------------------------------------------------') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d92f483b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ShuffleDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.string, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = ds_train.shuffle(buffer_size=5000)\n",
    "ds_valid = ds_valid.shuffle(buffer_size=5000)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4db37aaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(212,), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train = ds_train.map(preprocess)\n",
    "ds_valid = ds_valid.map(preprocess)\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9107fb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 512, 512, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 212), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch=8\n",
    "ds_train = ds_train.batch(batch).prefetch(2)\n",
    "ds_valid = ds_valid.batch(batch).prefetch(2)\n",
    "# Most dataset input pipelines should end with a call to prefetch. \n",
    "# This allows later elements to be prepared while the current element is being processed. \n",
    "# This often improves latency and throughput, at the cost of using additional memory to store prefetched elements.\n",
    "ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0fc4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(\"files\", \"model.h5\")\n",
    "csv_path = os.path.join(\"files\", \"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88d03bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Model \"\"\"\n",
    "model = build_model(input_shape, num_landmarks)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr))\n",
    "\n",
    "\"\"\" Training \"\"\"\n",
    "callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path, append=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ccee253",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\" Seeding \"\"\"\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48393d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   8/2271 [..............................] - ETA: 1:23:44 - loss: 0.6903"
     ]
    }
   ],
   "source": [
    "model.fit(ds_train,\n",
    "        validation_data=ds_train,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=callbacks\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aa9050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b512c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
